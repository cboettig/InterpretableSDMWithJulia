---
title: Initial training of the NBC
---

```{julia}
include(joinpath("code", "pkg.jl"))
include(joinpath("code", "nbc.jl"))
include(joinpath("code", "splitters.jl"))
include(joinpath("code", "confusion.jl"))
```

we train a nbc on a pair of variables (1, 12)

```{julia}
data = JLD.load("artifacts/data.jld")
y, X = data["y"], data["X"][:,:]
```

next up we split the data in two

```{julia}
idx, tidx = holdout(y, X; permute=true)
```

initial model

```{julia}
model1 = naivebayes(y[idx], X[idx,:])
prediction = vec(mapslices(model1, X[tidx,:]; dims=2))
ConfusionMatrix(prediction, y[tidx]) |> mcc
```

variable selection

```{julia}
available_variables = collect(axes(X, 2))
best_mcc = -Inf
while ~isempty(available_variables)
    scores = zeros(length(available_variables))
    for (i,v) in enumerate(available_variables)
        variable_pool = deleteat!(copy(available_variables),i)
        for fold in folds
            trn, vld = fold
            foldmodel = naivebayes(ty[trn], tX[trn,variable_pool])
            foldvalid = vec(mapslices(foldmodel, tX[vld,variable_pool]; dims=2))
            scores[i] += mcc(ConfusionMatrix(foldvalid, ty[vld]))
        end
    end
    scores ./= k
    best, i = findmax(scores)
    if best > best_mcc
        best_mcc = best
        deleteat!(available_variables, i)
    else
        break
    end
end
```

newmodel

initial tuning

```{julia}
thr = LinRange(0.0, 1.0, 50)
k = 10
C = zeros(ConfusionMatrix, (k, length(thr)))
ty, tX = y[idx], X[idx,available_variables]
folds = kfold(ty, tX; k=k, permute=true)
for (j,fold) in enumerate(folds)
    trn, vld = fold
    foldmodel = naivebayes(ty[trn], tX[trn,:])
    foldvalid = vec(mapslices(foldmodel, tX[vld,:]; dims=2))
    for (i,t) in enumerate(thr)
        C[j,i] = ConfusionMatrix(foldvalid, ty[vld], t)
    end
end
```

```{julia}
fig = Figure(; resolution=(900, 400))

gl = fig[1,1] = GridLayout()

ax_mcc = Axis(gl[1,1])

scores = mcc.(C)
σ = vec(std(scores; dims=1))
μ = vec(mean(scores; dims=1))

band!(ax_mcc, thr, μ-.5σ, μ+.5σ, color=:lightgrey)
scatterlines!(ax_mcc, thr, μ, color=:black)

xlims!(ax_mcc, low=0.0, high=1.0)
ylims!(ax_mcc, low=0.0)

_, m = findmax(μ)
vlines!(ax_mcc, thr[m])

current_figure()
```

retrain

```{julia}
model2 = naivebayes(ty, tX)
```

we make a map

```{julia}
predictors = [SpeciesDistributionToolkit._read_geotiff("artifacts/layers.tiff", SimpleSDMResponse; bandnumber=i) for i in axes(X, 2)]
prediction = similar(first(predictors))
Threads.@threads for k in keys(prediction)
    prediction[k] = model2([p[k] for p in predictors[available_variables]])
end
```

map the prediction

```{julia}
fig = Figure(; resolution=(900, 400))
ax = Axis(fig[1,1]; xlabel="Longitude", ylabel="Latitude", aspect=DataAspect())
hm = heatmap!(ax, prediction, colormap=Reverse(:roma), colorrange=(0., 1.))
Colorbar(fig[1,2], hm; tellheight=false)
current_figure()
```

uncertainty

```{julia}
function entropy(f)
    p = [f, 1-f]
    return -sum(p .* log2.(p))
end

fig = Figure(; resolution=(900, 400))
ax = Axis(fig[1,1]; xlabel="Longitude", ylabel="Latitude", aspect=DataAspect())
hm = heatmap!(ax, entropy.(prediction), colormap=Reverse(:tokyo), colorrange=(0., 1.))
Colorbar(fig[1,2], hm; tellheight=false)
current_figure()
```
