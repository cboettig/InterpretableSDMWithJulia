---
title: Initial training of the NBC
---

```{julia}
include(joinpath("code", "pkg.jl"))
include(joinpath("code", "nbc.jl"))
include(joinpath("code", "splitters.jl"))
include(joinpath("code", "confusion.jl"))
include(joinpath("code", "variableselection.jl"))
include(joinpath("code", "shapley.jl"))
```

we train a nbc on a pair of variables (1, 12)

```{julia}
data = JLD.load("artifacts/data.jld")
y, X = data["y"], data["X"][:,:]
```

next up we split the data in two

```{julia}
idx, tidx = holdout(y, X; permute=true)
ty, tX = y[idx], X[idx,:]
k = 10
folds = kfold(ty, tX; k=k, permute=true)
```

initial model

```{julia}
model1 = naivebayes(y[idx], X[idx,:])
prediction = vec(mapslices(model1, X[tidx,:]; dims=2))
ConfusionMatrix(prediction, y[tidx]) |> mcc
```

variable selection

```{julia}
available_variables = forwardselection(ty, tX, folds, naivebayes, mcc)
```

newmodel

initial tuning

```{julia}
ty, tX = y[idx], X[idx,available_variables]

thr = LinRange(0.0, 1.0, 250)
C = zeros(ConfusionMatrix, (k, length(thr)))
for (j,fold) in enumerate(folds)
    trn, vld = fold
    foldmodel = naivebayes(ty[trn], tX[trn,:])
    foldvalid = vec(mapslices(foldmodel, tX[vld,:]; dims=2))
    for (i,t) in enumerate(thr)
        C[j,i] = ConfusionMatrix(foldvalid, ty[vld], t)
    end
end
```

performance curve

```{julia}
fig = Figure(; resolution=(900, 400))

gl = fig[1,1] = GridLayout()

ax_mcc = Axis(gl[1,1])

scores = mcc.(C)
σ = vec(std(scores; dims=1))
μ = vec(mean(scores; dims=1))

band!(ax_mcc, thr, μ-.5σ, μ+.5σ, color=:lightgrey)
lines!(ax_mcc, thr, μ, color=:slategrey, linestyle=:dash)

xlims!(ax_mcc, low=0.0, high=1.0)
ylims!(ax_mcc, low=0.0)

_, m = findmax(μ)
vlines!(ax_mcc, thr[m])

current_figure()
```

retrain

```{julia}
model2 = naivebayes(ty, tX)
```

we make a map

```{julia}
predictors = [SpeciesDistributionToolkit._read_geotiff("artifacts/layers.tiff", SimpleSDMResponse; bandnumber=i) for i in axes(X, 2)]
prediction = similar(first(predictors))
Threads.@threads for k in keys(prediction)
    prediction[k] = model2([p[k] for p in predictors[available_variables]])
    if isnan(prediction[k])
        prediction[k] = 0.0
    end
end
```

map the prediction

```{julia}
fig = Figure(; resolution=(900, 400))
ax = Axis(fig[1,1]; xlabel="Longitude", ylabel="Latitude", aspect=DataAspect())
hm = heatmap!(ax, prediction, colormap=Reverse(:seaborn_icefire_gradient), colorrange=(0., 1.))
Colorbar(fig[1,2], hm; tellheight=false)
current_figure()
```

uncertainty

```{julia}
function entropy(f)
    p = [f, 1-f]
    return -sum(p .* log2.(p))
end

fig = Figure(; resolution=(900, 400))
ax = Axis(fig[1,1]; xlabel="Longitude", ylabel="Latitude", aspect=DataAspect())
hm = heatmap!(ax, entropy.(prediction), colormap=Reverse(:tokyo), colorrange=(0., 1.))
Colorbar(fig[1,2], hm; tellheight=false)
current_figure()
```

shapley values

```{julia}
shapval = [similar(first(predictors)) for i in 1:4]
Threads.@threads for k in keys(shapley1)
    x = [p[k] for p in predictors[available_variables]]
    for i in axes(shapval, 1)
        shapval[i][k] = shapleyvalues(model2, tX, x, i; M=50)
    end
end
```

map

```{julia}
fig = Figure(; resolution=(900, 400))

gl = fig[1,1] = GridLayout()

coords = CartesianIndices((1:2, 1:2))

for i in 1:length(coords)
    ax = Axis(gl[coords[i].I...])
    heatmap!(ax, shapval[i], colorrange=(-0.4,0.4), colormap=:diverging_gwv_55_95_c39_n256, aspect=DataAspect())
    hidexdecorations!(ax)
    hideydecorations!(ax)
end

rowgap!(gl, 0.0)
colgap!(gl, 0.0)

Colorbar(fig[1,2], colorrange=(-0.4, 0.5), colormap=:diverging_gwv_55_95_c39_n256; tellheight=false)
current_figure()
```

mosaic of most important variable in the top 4

```{julia}
heatmap(mosaic(argmax, map(abs, shapval)), colormap=:Set2_4)
```