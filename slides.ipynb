{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Interpretable Machine Learning\"\n",
        "subtitle: \"Answers that make sense, right out of the (black) box?\"\n",
        "author:\n",
        "    name: \"Timothée Poisot\"\n",
        "    email: timothee.poisot@umontreal.ca\n",
        "institute: \"Université de Montréal\"\n",
        "title-slide-attributes: \n",
        "  data-background-image: https://cdn.pixabay.com/photo/2018/07/14/17/07/raccoon-3537985_1280.jpg\n",
        "  data-background-opacity: \"0.25\"\n",
        "bibliography: references.bib\n",
        "csl: https://www.zotero.org/styles/trends-in-ecology-and-evolution\n",
        "---"
      ],
      "id": "1589ae32"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Overview\n",
        "\n",
        "-   Build a *simple* classifier to predict the distribution of a species\n",
        "\n",
        "-   Use this as an opportunity to talk about interpretable ML\n",
        "\n",
        "-   Discuss which biases are appropriate in a predictive model\n",
        "\n",
        "    ::: notes\n",
        "    Emphasize: importance of talking about the model more than getting the model right\n",
        "\n",
        "    We will look at SDM as a ML problem, then look at the ML problem as an ecological one\n",
        "    :::\n",
        "\n",
        "------------------------------------------------------------------------\n",
        "\n",
        "::: r-fit-text\n",
        "We care a lot about the\n",
        "\n",
        "**process**\n",
        "\n",
        "and only a little about the\n",
        "\n",
        "**product**\n",
        ":::\n",
        "\n",
        "------------------------------------------------------------------------\n",
        "\n",
        "## Raccoons!\n",
        "\n",
        "- Relatable (bag under eyes, love naps, out of shape, will fight over garbage)\n",
        "\n",
        "-   High volume of data\n",
        "\n",
        "-   Species of concern for zoonotic diseases\n",
        "\n",
        "-   Where can we find them in/around Québec?\n",
        "\n",
        "## Do try this at home!\n",
        "\n",
        "> Download the full project at `https://github.com/tpoisot/GEOBON2023-Julia-Workshop`\n"
      ],
      "id": "b9ea083a"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: Include the packages we need\n",
        "#| echo: true\n",
        "#| output: false\n",
        "include(joinpath(\"code\", \"pkg.jl\")); # Dependencies\n",
        "include(joinpath(\"code\", \"nbc.jl\")); # Naive Bayes Classifier\n",
        "include(joinpath(\"code\", \"splitters.jl\")); # Cross-validation\n",
        "include(joinpath(\"code\", \"confusion.jl\")); # Confusion matrix utilities\n",
        "include(joinpath(\"code\", \"variableselection.jl\")); # Variable selection\n",
        "include(joinpath(\"code\", \"shapley.jl\")); # Shapley values"
      ],
      "id": "Include-the-packages-we-need",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "::: notes\n",
        "**hand made**, this is not recommended (use MLJ instead), but useful to get to see how the language can be used for various tasks\n",
        ":::\n",
        "\n",
        "## To train a model, we need...\n",
        "\n",
        "A response variable $y$\n",
        "\n",
        ":   presence or absence of a species at a location identified by its latitude and longitude\n",
        "\n",
        "A series of predictors $\\mathbf{x}$\n",
        "\n",
        ":   bioclimatic variables\n",
        "\n",
        "A series of predictions $\\hat y$\n",
        "\n",
        ": which we will compare to the values of $y$\n",
        "\n",
        "::: notes\n",
        "Note that the process of making assumptions has *already* started here (we pick a set of variables we think are important)\n",
        ":::\n",
        "\n",
        "## Bioclimatic data\n",
        "\n",
        "We collect data from WorldClim2 @fick2017, using `SpeciesDistributionToolkit`\n"
      ],
      "id": "f5bedfc7"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: Download the BioClim data from WorldClim2\n",
        "#| eval: true\n",
        "#| echo: true\n",
        "#| output: false\n",
        "provider = RasterData(WorldClim2, BioClim)\n",
        "opts = (resolution=2.5, )\n",
        "boundingbox = (bottom=41.0, right=-59.5, left=-80.00, top=52.0)\n",
        "temperature = SimpleSDMPredictor(provider, layer=1; opts..., boundingbox...)"
      ],
      "id": "Download-the-BioClim-data-from-WorldClim2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then we use landcover data @tuanmu2014 to remove the great lakes:\n"
      ],
      "id": "93cacb44"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: Download and rescale the water data from EarthEnv\n",
        "#| eval: true\n",
        "#| echo: true\n",
        "#| output: false\n",
        "water = SimpleSDMPredictor(RasterData(EarthEnv, LandCover), layer=12; boundingbox...)\n",
        "land = replace(\n",
        "    coarsen(water, minimum, (5, 5)).<100,\n",
        "    false => nothing\n",
        ")"
      ],
      "id": "Download-and-rescale-the-water-data-from-EarthEnv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Species occurrence filtering\n",
        "\n",
        "We use the [GBIF] API through the `GBIF` package for *Julia* @dansereau2021 to get data about *Procyon lotor*\n",
        "\n",
        "  [GBIF]: http://gbif.org\n"
      ],
      "id": "9de16451"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: Get the species from GBIF\n",
        "#| eval: true\n",
        "#| echo: true\n",
        "#| output: false\n",
        "critter = taxon(\"Procyon lotor\"; strict=false)"
      ],
      "id": "Get-the-species-from-GBIF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We only consider occurrences within the bounding box!\n"
      ],
      "id": "3d122563"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: Get the initial round of occurrences\n",
        "#| eval: true\n",
        "#| echo: true\n",
        "#| output: false\n",
        "query = [\n",
        "    \"occurrenceStatus\" => \"PRESENT\",\n",
        "    \"hasCoordinate\" => true,\n",
        "    \"decimalLatitude\" => (boundingbox.bottom, boundingbox.top),\n",
        "    \"decimalLongitude\" => (boundingbox.left, boundingbox.right),\n",
        "    \"limit\" => 300,\n",
        "]\n",
        "observations = occurrences(critter, query...)"
      ],
      "id": "Get-the-initial-round-of-occurrences",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: Get extra data\n",
        "#| echo: false\n",
        "#| eval: true\n",
        "#| output: false\n",
        "for _ in 1:50\n",
        "    occurrences!(observations)\n",
        "end"
      ],
      "id": "Get-extra-data",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Where are we so far?\n"
      ],
      "id": "a5697e22"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "fig = Figure(; resolution=(900, 500))\n",
        "ax = Axis(fig[1,1]; xlabel=\"Longitude\", ylabel=\"Latitude\", aspect=DataAspect())\n",
        "hm = heatmap!(ax, mask(land, temperature), colormap=:dense)\n",
        "Colorbar(fig[1,2], hm; tellheight=false)\n",
        "scatter!(ax, observations; color=:black, marker=:cross, markersize=5)\n",
        "current_figure()"
      ],
      "id": "7fe0e38f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## WAIT!\n",
        "\n",
        "It's not serious ecology unless we use Phylopic:\n"
      ],
      "id": "e88a314b"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: Phylopic image\n",
        "#| echo: true\n",
        "#| output: false\n",
        "phylopic_uuid = Phylopic.imagesof(critter; items = 1)\n",
        "silhouette = phylopic_uuid |>\n",
        "    Phylopic.thumbnail |>\n",
        "    Downloads.download |>\n",
        "    Images.load"
      ],
      "id": "Phylopic-image",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "*Always* use the `Phylopic.attribution` function: `{julia} Phylopic.attribution(phylopic_uuid)`\n",
        "\n",
        "## Where are we so far?\n"
      ],
      "id": "7a03039c"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "silhouette_size = Vec2f(reverse(size(silhouette) ./ 1.5))\n",
        "\n",
        "scatter!(ax, [-76], [48.9]; marker = silhouette, markersize = silhouette_size, color=:white)\n",
        "current_figure()"
      ],
      "id": "726f0033",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Spatial thinning\n",
        "\n",
        "We limit the occurrences to one per grid cell, assigned to the center of the grid cell\n"
      ],
      "id": "b50d3be2"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: Make the layer for presences\n",
        "#| echo: true\n",
        "#| eval: true\n",
        "#| output: false\n",
        "presence_layer = mask(land, mask(temperature, observations, Bool))"
      ],
      "id": "Make-the-layer-for-presences",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Note that this syntax mixes layers (`temperature`, `land`) and occurrences (`observations`) types.\n",
        "\n",
        "## Background points generation\n",
        "\n",
        "We generate background points in a 200km radius around each point @barbet-massin2012 -- but we keep a 20km buffer with no background points:\n"
      ],
      "id": "aef42718"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: Make the pseudo-absence buffer\n",
        "#| eval: true\n",
        "#| echo: true\n",
        "#| output: false\n",
        "background = pseudoabsencemask(WithinRadius, presence_layer; distance = 200.0)\n",
        "buffer = pseudoabsencemask(WithinRadius, presence_layer; distance = 20.0)\n",
        "possible_background = .!(background .| (.! buffer))"
      ],
      "id": "Make-the-pseudo-absence-buffer",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And then we sample 4 background points out of every 10 occurrences:\n"
      ],
      "id": "04514e59"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: Make the absence layer\n",
        "#| echo: true\n",
        "#| eval: true\n",
        "#| output: false\n",
        "absence_layer = SpeciesDistributionToolkit.sample(\n",
        "    possible_background, \n",
        "    round(Int, 0.4*sum(presence_layer))\n",
        ")"
      ],
      "id": "Make-the-absence-layer",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Background points cleaning\n",
        "\n",
        "We can remove all of the information that is neither a presence nor a pseudo-absence\n"
      ],
      "id": "5be618a2"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: Pseudo-absence/presence remove\n",
        "#| output: false\n",
        "#| echo: true\n",
        "replace!(absence_layer, false => nothing)\n",
        "replace!(presence_layer, false => nothing)"
      ],
      "id": "Pseudo-absencepresence-remove",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data overview\n"
      ],
      "id": "23631abd"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "heatmap!(possible_background; colormap = cgrad([:transparent, :white]; alpha = 0.3))\n",
        "scatter!(ax, [-76], [48.9]; marker = silhouette, markersize = silhouette_size, color=:white)\n",
        "current_figure()"
      ],
      "id": "145ead75",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: Save the stack of layers\n",
        "#| echo: false\n",
        "#| output: false\n",
        "#| eval: true\n",
        "bioclim_clipped = [mask(land, SimpleSDMPredictor(provider; layer = l, opts..., boundingbox...)) for l in layers(provider)]\n",
        "SpeciesDistributionToolkit._write_geotiff(\"artifacts/layers.tiff\", bioclim_clipped)"
      ],
      "id": "Save-the-stack-of-layers",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Preparing the responses and variables\n"
      ],
      "id": "86ca31bc"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: Assemble y and X\n",
        "#| echo: true\n",
        "#| output: false\n",
        "Xpresence = hcat([bioclim_var[keys(presence_layer)] for bioclim_var in bioclim_clipped]...)\n",
        "ypresence = fill(true, length(presence_layer))\n",
        "Xabsence = hcat([bioclim_var[keys(absence_layer)] for bioclim_var in bioclim_clipped]...)\n",
        "yabsence = fill(false, length(absence_layer))\n",
        "X = vcat(Xpresence, Xabsence)\n",
        "y = vcat(ypresence, yabsence)"
      ],
      "id": "Assemble-y-and-X",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Serializing the data to a file\n"
      ],
      "id": "ffc90eea"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: Save the data\n",
        "#| output: false\n",
        "#| echo: true\n",
        "bclay = layers(RasterData(WorldClim2, BioClim))\n",
        "bcdes = layerdescriptions(RasterData(WorldClim2, BioClim))\n",
        "presences = Tuple.(keys(presence_layer))\n",
        "absences = Tuple.(keys(absence_layer))\n",
        "variables = [(bc, bcdes[bc]) for bc in bclay]\n",
        "JLD.@save \"artifacts/data.jld\" X y presences absences variables"
      ],
      "id": "Save-the-data",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## The model - Naive Bayes Classifier\n",
        "\n",
        "Prediction:\n",
        "\n",
        "$$\n",
        "P(+|x) = \\frac{P(+)}{P(x)}P(x|+)\n",
        "$$ \n",
        "\n",
        "Decision rule:\n",
        "\n",
        "$$\n",
        "\\hat y = \\text{argmax}_j \\, P(\\mathbf{c}_j)\\prod_i P(\\mathbf{x}_i|\\mathbf{c}_j)\n",
        "$$ \n",
        "\n",
        "## Cross-validation\n",
        "\n",
        "We keep an *unseen* testing set -- this will be used at the very end\n"
      ],
      "id": "0e20eedf"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: Testing set\n",
        "#| echo: true\n",
        "#| output: false\n",
        "idx, tidx = holdout(y, X; permute=true)"
      ],
      "id": "Testing-set",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For *validation*, we will run k-folds ($k=12$)\n"
      ],
      "id": "a0421d85"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: k-folds\n",
        "#| echo: true\n",
        "#| output: false\n",
        "ty, tX = y[idx], X[idx,:]\n",
        "k = 12\n",
        "folds = kfold(ty, tX; k=k, permute=true)"
      ],
      "id": "k-folds",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## A note on cross-validation\n",
        "\n",
        "- All models share the same folds (we can compare the validation performance across experiments)\n",
        "\n",
        "- Testing set is *only* for future evaluation (we will use it once and report the expected performance)\n",
        "\n",
        "- Comparison of model performance: average over validation folds\n",
        "\n",
        "## Baseline performance\n",
        "\n",
        "We need to get a sense of how hard the problem is:\n"
      ],
      "id": "3cc3fa22"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "#| output: false\n",
        "C0 = zeros(ConfusionMatrix, length(folds))\n",
        "for (i,f) in enumerate(folds)\n",
        "    trn, val = f\n",
        "    foldmodel = naivebayes(ty[trn], tX[trn,:])\n",
        "    foldpred = vec(mapslices(foldmodel, tX[val,:]; dims=2))\n",
        "    C0[i] = ConfusionMatrix(foldpred, ty[val])\n",
        "end"
      ],
      "id": "f4f515e4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Measures on the confusion matrix\n",
        "\n",
        "|                                   | Initial model                             |\n",
        "|-----------------------------------|-------------------------------------------|\n",
        "| FPR              | `{julia} round(mean(fpr.(C0)); digits=2)` |\n",
        "| FNR             | `{julia} round(mean(fnr.(C0)); digits=2)` |\n",
        "| TPR           | `{julia} round(mean(tpr.(C0)); digits=2)` |\n",
        "| TNR           | `{julia} round(mean(tnr.(C0)); digits=2)` |\n",
        "| MCC | `{julia} round(mean(mcc.(C0)); digits=2)` |\n",
        "\n",
        "## Variable selection\n",
        "\n",
        "We add variables one at a time, until the Matthew's Correlation Coefficient stops increasing:\n"
      ],
      "id": "ab94c794"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "#| output: false\n",
        "available_variables = forwardselection(ty, tX, folds, naivebayes, mcc)"
      ],
      "id": "6ffe60f1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This method identifies `{julia} length(available_variables)` variables, some of which are:\n",
        "\n",
        "1.  `{julia} variables[available_variables[1]][2]`\n",
        "\n",
        "2.  `{julia} variables[available_variables[2]][2]`\n",
        "\n",
        "3.  `{julia} variables[available_variables[3]][2]`\n",
        "\n",
        "## Discuss - can we force variable selection?\n",
        "\n",
        "- constrained variable selection\n",
        "\n",
        "- VIF + variable selection\n",
        "\n",
        "- PCA?\n",
        "\n",
        "## Model with variable selection\n"
      ],
      "id": "bbeca29a"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "#| output: false\n",
        "C1 = zeros(ConfusionMatrix, length(folds))\n",
        "for (i,f) in enumerate(folds)\n",
        "    trn, val = f\n",
        "    foldmodel = naivebayes(ty[trn], tX[trn,available_variables])\n",
        "    foldpred = vec(mapslices(foldmodel, tX[val,available_variables]; dims=2))\n",
        "    C1[i] = ConfusionMatrix(foldpred, ty[val])\n",
        "end"
      ],
      "id": "c63578f5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Measures on the confusion matrix\n",
        "\n",
        "|                                   | Initial model                             | Var. sel.                             |\n",
        "|-----------------------------------|-------------------------------------------|-------------------------------------------|\n",
        "| FPR              | `{julia} round(mean(fpr.(C0)); digits=2)` | `{julia} round(mean(fpr.(C1)); digits=2)` |\n",
        "| FNR             | `{julia} round(mean(fnr.(C0)); digits=2)` | `{julia} round(mean(fnr.(C1)); digits=2)` |\n",
        "| TPR           | `{julia} round(mean(tpr.(C0)); digits=2)` | `{julia} round(mean(tpr.(C1)); digits=2)` |\n",
        "| TNR           | `{julia} round(mean(tnr.(C0)); digits=2)` | `{julia} round(mean(tnr.(C1)); digits=2)` |\n",
        "| MCC | `{julia} round(mean(mcc.(C0)); digits=2)` | `{julia} round(mean(mcc.(C1)); digits=2)` |\n",
        "\n",
        "## How do we make the model better?\n",
        "\n",
        "The NBC is a *probabilistic classifier* returning $P(+|\\mathbf{x})$\n",
        "\n",
        "The *decision rule* is to assign a presence when $P(\\cdot) > 0.5$\n",
        "\n",
        "But $P(\\cdot) > \\tau$ is a far more general approach, and we can use learning curves to identify $\\tau$\n",
        "\n",
        "## Thresholding the model\n"
      ],
      "id": "0e5de027"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "#| output: false\n",
        "ty, tX = y[idx], X[idx,available_variables]\n",
        "thr = LinRange(0.0, 1.0, 350)\n",
        "C = zeros(ConfusionMatrix, (k, length(thr)))\n",
        "for (j,fold) in enumerate(folds)\n",
        "    trn, vld = fold\n",
        "    foldmodel = naivebayes(ty[trn], tX[trn,:])\n",
        "    foldvalid = vec(mapslices(foldmodel, tX[vld,:]; dims=2))\n",
        "    for (i,t) in enumerate(thr)\n",
        "        C[j,i] = ConfusionMatrix(foldvalid, ty[vld], t)\n",
        "    end\n",
        "end"
      ],
      "id": "4b5d74e9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## But how do we pick the threshold?\n"
      ],
      "id": "2bd9dc37"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "fig = Figure(; resolution=(900, 450))\n",
        "\n",
        "ax_mcc = Axis(fig[1,1], xlab=\"Threshold\", ylab=\"MCC\")\n",
        "\n",
        "scores = mcc.(C)\n",
        "σ = vec(std(scores; dims=1))\n",
        "μ = vec(mean(scores; dims=1))\n",
        "\n",
        "band!(ax_mcc, thr, μ-σ, μ+σ, color=:lightgrey)\n",
        "\n",
        "lines!(ax_mcc, thr, μ, color=:black, linewidth=3)\n",
        "\n",
        "xlims!(ax_mcc, low=0.0, high=1.0)\n",
        "ylims!(ax_mcc, low=0.0, high=1.0)\n",
        "\n",
        "_, m = findmax(μ)\n",
        "vlines!(ax_mcc, thr[m], color=:red)\n",
        "\n",
        "ax_roc = Axis(fig[1,2], xlab=\"False Positive Rate\", ylab=\"True Positive Rate\")\n",
        "\n",
        "for i in axes(C, 1)\n",
        "    lines!(ax_roc, fpr.(C[i,:]), tpr.(C[i,:]), color=:lightgrey)\n",
        "end\n",
        "\n",
        "xlims!(ax_roc, low=0.0, high=1.0)\n",
        "ylims!(ax_roc, low=0.0, high=1.0)\n",
        "\n",
        "current_figure()"
      ],
      "id": "03ade0ad",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Optimal threshold\n"
      ],
      "id": "403776d3"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "τ = thr[m]"
      ],
      "id": "e85cfe09",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Tuned model with selected variables\n"
      ],
      "id": "8f5d9226"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "#| output: false\n",
        "C2 = zeros(ConfusionMatrix, length(folds))\n",
        "for (i,f) in enumerate(folds)\n",
        "    trn, val = f\n",
        "    foldmodel = naivebayes(ty[trn], tX[trn,:])\n",
        "    foldpred = vec(mapslices(foldmodel, tX[val,:]; dims=2))\n",
        "    C2[i] = ConfusionMatrix(foldpred, ty[val], thr[m])\n",
        "end"
      ],
      "id": "89f3f254",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Measures on the confusion matrix\n",
        "\n",
        "|                                   | Initial model                             | Var. sel.                             | Tuned                            |\n",
        "|-----------------------------------|-------------------------------------------|-------------------------------------------|-------------------------------------------|\n",
        "| FPR              | `{julia} round(mean(fpr.(C0)); digits=2)` | `{julia} round(mean(fpr.(C1)); digits=2)` | `{julia} round(mean(fpr.(C2)); digits=2)` |\n",
        "| FNR             | `{julia} round(mean(fnr.(C0)); digits=2)` | `{julia} round(mean(fnr.(C1)); digits=2)` | `{julia} round(mean(fnr.(C2)); digits=2)` |\n",
        "| TPR           | `{julia} round(mean(tpr.(C0)); digits=2)` | `{julia} round(mean(tpr.(C1)); digits=2)` | `{julia} round(mean(tpr.(C2)); digits=2)` |\n",
        "| TNR           | `{julia} round(mean(tnr.(C0)); digits=2)` | `{julia} round(mean(tnr.(C1)); digits=2)` | `{julia} round(mean(tnr.(C2)); digits=2)` |\n",
        "| MCC | `{julia} round(mean(mcc.(C0)); digits=2)` | `{julia} round(mean(mcc.(C1)); digits=2)` | `{julia} round(mean(mcc.(C2)); digits=2)` |\n",
        "\n",
        "## Tuned model performance\n",
        "\n",
        "We can retrain over *all* the training data\n"
      ],
      "id": "45479b0a"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "#| output: false\n",
        "finalmodel = naivebayes(ty, tX)\n",
        "prediction = vec(mapslices(finalmodel, X[tidx,available_variables]; dims=2))\n",
        "Cf = ConfusionMatrix(prediction, y[tidx], thr[m])"
      ],
      "id": "aa1bbf70",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Estimated performance\n",
        "\n",
        "\n",
        "|                                   | Final model                             |\n",
        "|-----------------------------------|-------------------------------------------|\n",
        "| FPR              | `{julia} round(fpr(Cf); digits=2)` |\n",
        "| FNR             | `{julia} round(fnr(Cf); digits=2)` |\n",
        "| TPR           | `{julia} round(tpr(Cf); digits=2)` |\n",
        "| TNR           | `{julia} round(tnr(Cf); digits=2)` |\n",
        "| MCC | `{julia} round(mcc(Cf); digits=2)` |\n",
        "\n",
        "## Acceptable bias\n",
        "\n",
        "- false positives: we expect that our knowledge of the distribution is incomplete!\n",
        "\n",
        "- false negatives: we used a heuristic for background points!\n",
        "\n",
        "## Prediction for each pixel\n"
      ],
      "id": "a6b27d6b"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "#| output: false\n",
        "predictors = [SpeciesDistributionToolkit._read_geotiff(\"artifacts/layers.tiff\", SimpleSDMResponse; bandnumber=i) for i in axes(X, 2)]\n",
        "prediction = similar(first(predictors))\n",
        "Threads.@threads for k in keys(prediction)\n",
        "    prediction[k] = finalmodel([p[k] for p in predictors[available_variables]])\n",
        "    if isnan(prediction[k])\n",
        "        prediction[k] = 0.0\n",
        "    end\n",
        "end"
      ],
      "id": "af99c025",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Tuned model - predictions\n"
      ],
      "id": "67478f67"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "#| output: true\n",
        "fig = Figure(; resolution=(900, 500))\n",
        "ax = Axis(fig[1,1]; xlabel=\"Longitude\", ylabel=\"Latitude\", aspect=DataAspect())\n",
        "hm = heatmap!(ax, prediction, colormap=Reverse(:linear_gow_60_85_c27_n256), colorrange=(0., 1.))\n",
        "Colorbar(fig[1,2], hm; tellheight=false)\n",
        "current_figure()"
      ],
      "id": "6886c778",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Tuned model - uncertainty\n"
      ],
      "id": "2e88a0c5"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "#| output: true\n",
        "function entropy(f)\n",
        "    p = [f, 1-f]\n",
        "    return -sum(p .* log2.(p))\n",
        "end\n",
        "\n",
        "fig = Figure(; resolution=(900, 500))\n",
        "ax = Axis(fig[1,1]; xlabel=\"Longitude\", ylabel=\"Latitude\", aspect=DataAspect())\n",
        "hm = heatmap!(ax, entropy.(prediction), colormap=Reverse(:linear_gow_60_85_c27_n256), colorrange=(0., 1.))\n",
        "Colorbar(fig[1,2], hm; tellheight=false)\n",
        "current_figure()"
      ],
      "id": "95e7814d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Tuned model - range\n"
      ],
      "id": "3628f9b5"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "#| output: true\n",
        "fig = Figure(; resolution=(900, 500))\n",
        "ax = Axis(fig[1,1]; xlabel=\"Longitude\", ylabel=\"Latitude\", aspect=DataAspect())\n",
        "hm = heatmap!(prediction .>= thr[m]; colormap = cgrad([:lightgrey, :black]; alpha = 0.3))\n",
        "scatter!(ax, observations; color=:black, marker=:cross, markersize=5)\n",
        "scatter!(ax, [-76], [48.9]; marker = silhouette, markersize = silhouette_size, color=:white)\n",
        "Colorbar(fig[1,2], hm; tellheight=false)\n",
        "current_figure()"
      ],
      "id": "97ffb397",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Predicting the predictions?\n",
        "\n",
        "Shapley values (Monte-Carlo approximation): if we mix the variables across two observations, how important is the $i$-th variable?\n",
        "\n",
        "Expresses \"importance\" as an additive factor on top of the *average* prediction (here: average prob. of occurrence)\n"
      ],
      "id": "fc84437e"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "#| output: false\n",
        "shapval = [similar(first(predictors)) for i in eachindex(available_variables)]\n",
        "Threads.@threads for k in keys(shapval[1])\n",
        "    x = [p[k] for p in predictors[available_variables]]\n",
        "    for i in axes(shapval, 1)\n",
        "        shapval[i][k] = shapleyvalues(finalmodel, tX, x, i; M=50)\n",
        "        if isnan(shapval[i][k])\n",
        "            shapval[i][k] = 0.0\n",
        "        end\n",
        "    end\n",
        "end"
      ],
      "id": "0e82b9bf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Sort the available variables by importance\n"
      ],
      "id": "fcb9bad9"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "varimp = sum.(map(abs, shapval))\n",
        "varimp ./= sum(varimp)\n",
        "for v in sortperm(varimp, rev=true)\n",
        "    vname = variables[available_variables[v]][2]\n",
        "    vctr = round(Int, varimp[v]*100)\n",
        "    println(\"$(vname) - $(vctr)%\")\n",
        "end"
      ],
      "id": "17dc1417",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "There is a difference between **contributing to model performance** and **contributing to model explanability**\n",
        "\n",
        "## Mapping the top three variables\n"
      ],
      "id": "59c0b06e"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "#| output: true\n",
        "fig = Figure(; resolution=(900, 800))\n",
        "\n",
        "gl = fig[1,1] = GridLayout()\n",
        "\n",
        "fpos = 1\n",
        "for i in sortperm(varimp; rev=true)[1:3]\n",
        "    ax_mp = Axis(gl[fpos,1])\n",
        "    scl = maximum(abs.(extrema(shapval[i]))).*(-1,1)\n",
        "    heatmap!(ax_mp, shapval[i], colorrange=scl, colormap=Reverse(:diverging_bwr_20_95_c54_n256), aspect=DataAspect())\n",
        "    hidexdecorations!(ax_mp)\n",
        "    hideydecorations!(ax_mp)\n",
        "\n",
        "    ax_pr = Axis(gl[fpos,2], title=variables[available_variables[i]][2])\n",
        "    ylims!(ax_pr, scl)\n",
        "    hexbin!(ax_pr, predictors[available_variables[i]], shapval[i], bins=200, colormap=:linear_bgyw_15_100_c67_n256)\n",
        "    fpos += 1\n",
        "end\n",
        "\n",
        "current_figure()"
      ],
      "id": "47773308",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Mapping the most determinant predictor\n"
      ],
      "id": "9bae45b6"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "cmap = Symbol(\"Set2_$(length(available_variables))\")\n",
        "fig = Figure(; resolution=(900, 500))\n",
        "ax = Axis(fig[1,1]; xlabel=\"Longitude\", ylabel=\"Latitude\", aspect=DataAspect())\n",
        "hm = heatmap!(ax, mosaic(argmax, map(abs, shapval)), colormap=cmap)\n",
        "Colorbar(fig[1,2], hm; tellheight=false)\n",
        "current_figure()"
      ],
      "id": "ca0a909f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Take-home\n",
        "\n",
        "- building a model is *incremental*\n",
        "\n",
        "- each step adds arbitrary decisions we can control for, justify, or live with\n",
        "\n",
        "- we can provide explanations for every single prediction\n",
        "\n",
        "- free online textbook (in development) at `https://tpoisot.github.io/DataSciForBiodivSci/`\n",
        "\n",
        "## References"
      ],
      "id": "0b12023e"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "julia-1.9",
      "language": "julia",
      "display_name": "Julia 1.9.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}