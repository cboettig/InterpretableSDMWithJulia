---
title: "Interpretable Machine Learning"
subtitle: "Answers that make sense, right out of the (black) box?"
author:
    name: "Timothée Poisot"
    email: timothee.poisot@umontreal.ca
institute: "Université de Montréal"
title-slide-attributes: 
  data-background-image: https://cdn.pixabay.com/photo/2018/07/14/17/07/raccoon-3537985_1280.jpg
  data-background-opacity: "0.25"
bibliography: references.bib
csl: https://www.zotero.org/styles/trends-in-ecology-and-evolution
---

## Overview

-   Build a *simple* classifier to predict the distribution of a species

-   Use this as an opportunity to talk about interpretable ML

-   Discuss which biases are appropriate in a predictive model

    ::: notes
    Emphasize: importance of talking about the model more than getting the model right

    We will look at SDM as a ML problem, then look at the ML problem as an ecological one
    :::

------------------------------------------------------------------------

::: r-fit-text
We care a lot about the

**process**

and only a little about the

**product**
:::

------------------------------------------------------------------------

## Raccoons!

-   High volume of data

-   Species of concern for zoonotic diseases

-   Where can we find them in/around Québec?

## Do try this at home!

```{julia}
#| echo: true
#| output: false
include(joinpath("code", "pkg.jl")); # Dependencies
include(joinpath("code", "nbc.jl")); # Naive Bayes Classifier
include(joinpath("code", "splitters.jl")); # Cross-validation
include(joinpath("code", "confusion.jl")); # Confusion matrix utilities
include(joinpath("code", "variableselection.jl")); # Variable selection
include(joinpath("code", "shapley.jl")); # Shapley values
```

::: notes
**hand made**, this is not recommended (use MLJ instead), but useful to get to see how the language can be used for various tasks
:::

## To train a model, we need...

A response variable $y$

:   presence or absence of a species at a location identified by its latitude and longitude

A series of predictors $\mathbf{x}$

:   bioclimatic variables

::: notes
Note that the process of making assumptions has *already* started here (we pick a set of variables we think are important)
:::

## Bioclimatic data

We collect data from WorldClim2 @fick2017, using `SpeciesDistributionToolkit`

```{julia}
#| eval: false
#| echo: true
provider = RasterData(WorldClim2, BioClim)
opts = (resolution=2.5, )
boundingbox = (bottom=41.0, right=-59.5, left=-80.00, top=52.0)
temperature = SimpleSDMPredictor(provider, layer=1; opts..., boundingbox...)
```

Then we use landcover data @tuanmu2014 to remove the great lakes:

```{julia}
#| eval: false
#| echo: true
water = SimpleSDMPredictor(RasterData(EarthEnv, LandCover), layer=12; boundingbox...)
land = replace(coarsen(water, minimum, (5, 5)).<100, false => nothing)
```

## Species occurrence filtering

We use the [GBIF] API through the `GBIF` package for *Julia* @dansereau2021 to get data about *Procyon lotor*

  [GBIF]: http://gbif.org

```{julia}
#| eval: false
#| echo: true
critter = taxon("Procyon lotor"; strict=false)
```

We only consider occurrences within the bounding box!

```{julia}
#| eval: false
#| echo: true
query = [
    "occurrenceStatus" => "PRESENT",
    "hasCoordinate" => true,
    "decimalLatitude" => (boundingbox.bottom, boundingbox.top),
    "decimalLongitude" => (boundingbox.left, boundingbox.right),
    "limit" => 300,
]
observations = occurrences(critter, query...)
```

## Spatial thinning

We limit the occurrences to one per grid cell, assigned to the center of the grid cell

```{julia}
#| echo: true
#| eval: false
presence_layer = mask(land, mask(temperature, observations, Bool))
```

## Background points

We generate background points in a 200km radius around each point @barbet-massin2012 -- but we keep a 20km buffer with no background points:

```{julia}
#| eval: false
#| echo: true
background = pseudoabsencemask(WithinRadius, presence_layer; distance = 200.0)
buffer = pseudoabsencemask(WithinRadius, presence_layer; distance = 20.0)
possible_background = background-buffer
```

And then we sample 4 background points out of every 10 occurrences:

```{julia}
#| echo: true
#| eval: false
absence_layer = SpeciesDistributionToolkit.sample(
    possible_background, 
    round(Int, 0.4*sum(presence_layer))
)
```

## Overview of the data

**TODO** figure

## The model

## How predictions are made

## Getting started

The raw data come pre-packaged with these slides:

```{julia}
#| echo: true
#| output: false
data = JLD.load("artifacts/data.jld")
y, X = data["y"], data["X"][:,:]
list_of_variables = data["variables"]
```

Cross-validation strategy

```{julia}
#| echo: true
#| output: false
idx, tidx = holdout(y, X; permute=true)
ty, tX = y[idx], X[idx,:]
k = 12
folds = kfold(ty, tX; k=k, permute=true)
```

## A note on cross-validation

all models share the same folds

testing set only for future evaluation

comparison: average validation performance

## Baseline performance

We need to get a sense of how hard the problem is:

```{julia}
#| echo: true
#| output: false
model1 = naivebayes(ty, tX)
prediction = vec(mapslices(model1, X[tidx,:]; dims=2))
C0 = ConfusionMatrix(prediction, y[tidx])
```

The usual measures on the confusion matrix:

| Measure                           | Value                              |
|-----------------------------------|------------------------------------|
| False positive rate               | `{julia} round(fpr(C0); digits=2)` |
| False negative rate               | `{julia} round(fnr(C0); digits=2)` |
| True positive rate                | `{julia} round(tpr(C0); digits=2)` |
| True negative rate                | `{julia} round(tnr(C0); digits=2)` |
| Matthew's correlation coefficient | `{julia} round(mcc(C0); digits=2)` |

## Variable selection results

We add variables one at a time, until the Matthew's Correlation Coefficient stops increasing:

```{julia}
#| echo: true
#| output: false
available_variables = forwardselection(ty, tX, folds, naivebayes, mcc)
```

The `{julia} length(available_variables)` variables returned by this step are:

1.  `{julia} list_of_variables[available_variables[1]][2]`

2.  `{julia} list_of_variables[available_variables[2]][2]`

3.  `{julia} list_of_variables[available_variables[3]][2]`

4.  `{julia} list_of_variables[available_variables[4]][2]`

5.  `{julia} list_of_variables[available_variables[5]][2]`

## Discuss - can we force variable selection?

## How do we make the model better?

The NBC is a *probabilistic classifier* returning $P(+|\mathbf{x})$

The *decision rule* is to assign a presence when $P(\cdot) > 0.5$

But $P(\cdot) > \tau$ is a far more general approach, and we can use learning curves to identify $\tau$

## Thresholding the model

```{julia}
#| echo: true
#| output: false
ty, tX = y[idx], X[idx,available_variables]
thr = LinRange(0.0, 1.0, 350)
C = zeros(ConfusionMatrix, (k, length(thr)))
for (j,fold) in enumerate(folds)
    trn, vld = fold
    foldmodel = naivebayes(ty[trn], tX[trn,:])
    foldvalid = vec(mapslices(foldmodel, tX[vld,:]; dims=2))
    for (i,t) in enumerate(thr)
        C[j,i] = ConfusionMatrix(foldvalid, ty[vld], t)
    end
end
```

## But how do we pick the threshold?

```{julia}
#| echo: false
fig = Figure(; resolution=(900, 450))

ax_mcc = Axis(fig[1,1])

scores = mcc.(C)
σ = vec(std(scores; dims=1))
μ = vec(mean(scores; dims=1))

band!(ax_mcc, thr, μ-σ, μ+σ, color=:lightgrey)

lines!(ax_mcc, thr, μ, color=:black, linewidth=3)

xlims!(ax_mcc, low=0.0, high=1.0)
ylims!(ax_mcc, low=0.0, high=1.0)

_, m = findmax(μ)
vlines!(ax_mcc, thr[m])


ax_roc = Axis(fig[1,2])

for i in axes(C, 1)
    lines!(ax_roc, fpr.(C[i,:]), tpr.(C[i,:]), color=:lightgrey)
end

xlims!(ax_roc, low=0.0, high=1.0)
ylims!(ax_roc, low=0.0, high=1.0)


current_figure()
```

## Tuned model performance

We can retrain over *all* the training data

```{julia}
#| echo: true
#| output: false
model2 = naivebayes(ty, tX)
prediction2 = vec(mapslices(model2, X[tidx,available_variables]; dims=2))
C1 = ConfusionMatrix(prediction2, y[tidx])
```

Note that we are re-using the testing data here, which is a pretty big no-no in practice, but we care about documenting the performance *had we stopped at the previous step*.

## Discuss - is this better?

| Measure                           | Initial model                      | **Tuned model**                    |
|----------------------------|------------------------|--------------------|
| False positive rate               | `{julia} round(fpr(C0); digits=2)` | `{julia} round(fpr(C1); digits=2)` |
| False negative rate               | `{julia} round(fnr(C0); digits=2)` | `{julia} round(fnr(C1); digits=2)` |
| True positive rate                | `{julia} round(tpr(C0); digits=2)` | `{julia} round(tpr(C1); digits=2)` |
| True negative rate                | `{julia} round(tnr(C0); digits=2)` | `{julia} round(tnr(C1); digits=2)` |
| Matthew's correlation coefficient | `{julia} round(mcc(C0); digits=2)` | `{julia} round(mcc(C1); digits=2)` |

## Estimated performance

## Acceptable bias

## Prediction for each pixel

```{julia}
#| echo: true
#| output: false
predictors = [SpeciesDistributionToolkit._read_geotiff("artifacts/layers.tiff", SimpleSDMResponse; bandnumber=i) for i in axes(X, 2)]
prediction = similar(first(predictors))
Threads.@threads for k in keys(prediction)
    prediction[k] = model2([p[k] for p in predictors[available_variables]])
    if isnan(prediction[k])
        prediction[k] = 0.0
    end
end
```

## Tuned model - visualized

```{julia}
#| echo: false
#| output: true
fig = Figure(; resolution=(900, 400))
ax = Axis(fig[1,1]; xlabel="Longitude", ylabel="Latitude", aspect=DataAspect())
hm = heatmap!(ax, prediction, colormap=Reverse(:curl), colorrange=(0., 1.))
Colorbar(fig[1,2], hm; tellheight=false)
current_figure()
```

## Acceptable bias - revisited

## Tuned model - uncertainty

```{julia}
#| echo: false
#| output: true
function entropy(f)
    p = [f, 1-f]
    return -sum(p .* log2.(p))
end

fig = Figure(; resolution=(900, 400))
ax = Axis(fig[1,1]; xlabel="Longitude", ylabel="Latitude", aspect=DataAspect())
hm = heatmap!(ax, entropy.(prediction), colormap=Reverse(:tokyo), colorrange=(0., 1.))
Colorbar(fig[1,2], hm; tellheight=false)
current_figure()
```

## How predictions are made - revisited

```{julia}
#| echo: true
#| output: false
shapval = [similar(first(predictors)) for i in eachindex(available_variables)]
Threads.@threads for k in keys(shapval[1])
    x = [p[k] for p in predictors[available_variables]]
    for i in axes(shapval, 1)
        shapval[i][k] = shapleyvalues(model2, tX, x, i; M=50)
        if isnan(shapval[i][k])
            shapval[i][k] = 0.0
        end
    end
end
```

## Mapping the explanatory variables

```{julia}
#| echo: false
#| output: true
fig = Figure(; resolution=(900, 800))

gl = fig[1,1] = GridLayout()

for i in 1:3
    ax_mp = Axis(gl[i,1])
    scl = maximum(abs.(extrema(shapval[i]))).*(-1,1)
    heatmap!(ax_mp, shapval[i], colorrange=scl, colormap=:cork, aspect=DataAspect())
    hidexdecorations!(ax_mp)
    hideydecorations!(ax_mp)

    ax_pr = Axis(gl[i,2], title=list_of_variables[available_variables[i]][2])
    ylims!(ax_pr, scl)
    hexbin!(ax_pr, predictors[available_variables[i]], shapval[i], bins=200)
end

#rowgap!(gl, 10.0)

current_figure()
```

## Take-home

## References